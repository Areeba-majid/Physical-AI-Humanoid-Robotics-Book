"""RAG (Retrieval-Augmented Generation) service for the AI textbook platform."""

import os
from typing import List, Optional, Dict, Any
from datetime import datetime

from google.generativeai import GenerativeModel
import google.generativeai as genai

from src.utils.embedding_utils import search_similar
from src.models.chat_interaction import ChatInteraction, Citation
from src.database.repository import BaseRepository
from src.utils.exceptions import AIServiceException, EmbeddingException
from src.utils.logging import log_ai_interaction, app_logger


class ChatInteractionRepository(BaseRepository[ChatInteraction]):
    """Repository for chat interaction operations."""

    def __init__(self):
        super().__init__(ChatInteraction, "chat_interactions")


class RAGService:
    """Service for Retrieval-Augmented Generation functionality."""

    def __init__(self):
        # Initialize Gemini model
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable is not set")

        genai.configure(api_key=api_key)
        self.model = GenerativeModel('gemini-pro')  # Using gemini-pro for text generation
        self.chat_history_repo = ChatInteractionRepository()

    async def generate_response(
        self,
        user_message: str,
        user_id: str,
        session_id: str,
        context: Optional[Dict[str, Any]] = None
    ) -> ChatInteraction:
        """Generate a response using RAG approach with context from textbook content."""

        try:
            # Search for relevant content in the knowledge base
            relevant_content = await self._search_relevant_content(user_message, context)

            # Create a context prompt for the AI model
            context_prompt = self._build_context_prompt(user_message, relevant_content)

            # Generate response using Gemini
            response = await self._generate_with_gemini(context_prompt, user_message)

            # Extract citations from relevant content
            citations = self._extract_citations(relevant_content)

            # Create chat interaction record
            chat_interaction = ChatInteraction(
                id="",  # Will be generated by the repository
                user_id=user_id,
                session_id=session_id,
                user_message=user_message,
                ai_response=response,
                citations=citations,
                context_used=context_prompt if context else user_message,
                created_at=datetime.utcnow()
            )

            # Save the interaction
            saved_interaction = await self.chat_history_repo.create(chat_interaction)

            # Log the AI interaction
            log_ai_interaction(
                user_message,
                response,
                user_id=user_id,
                session_id=session_id,
                context=context
            )

            return saved_interaction

        except Exception as e:
            app_logger.exception(
                "Error in RAG service",
                user_id=user_id,
                session_id=session_id,
                context=context
            )
            raise AIServiceException(f"Failed to generate response: {str(e)}")

    async def _search_relevant_content(self, query: str, context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Search for relevant content in the knowledge base using embeddings."""
        try:
            # Determine which collection to search based on context
            collection_name = "textbook_content"
            if context and "chapter_id" in context:
                # In a real implementation, we might search within a specific chapter
                pass

            # Perform similarity search
            search_results = search_similar(
                collection_name=collection_name,
                query=query,
                top_k=5  # Retrieve top 5 most similar chunks
            )

            if search_results is None:
                return []

            return search_results

        except Exception as e:
            app_logger.error(f"Error searching for relevant content: {str(e)}")
            raise EmbeddingException(f"Failed to search for relevant content: {str(e)}")

    def _build_context_prompt(self, user_message: str, relevant_content: List[Dict[str, Any]]) -> str:
        """Build a context prompt incorporating relevant content."""
        if not relevant_content:
            # If no relevant content is found, create a general prompt
            return (
                f"Please answer the following question: {user_message}. "
                f"If you don't have specific information, please say so."
            )

        # Build context from relevant content
        context_snippets = []
        for content in relevant_content:
            snippet = content.get("text", "")
            if len(snippet) > 500:  # Truncate long snippets
                snippet = snippet[:500] + "..."
            context_snippets.append(snippet)

        context_text = "\n\n".join(context_snippets)

        return (
            f"Based on the following textbook content, please answer the question. "
            f"Include citations to the provided content where appropriate:\n\n"
            f"Textbook Content:\n{context_text}\n\n"
            f"Question: {user_message}\n\n"
            f"Please structure your response with relevant citations."
        )

    async def _generate_with_gemini(self, context_prompt: str, original_question: str) -> str:
        """Generate a response using the Gemini model."""
        try:
            # Generate content using the model
            response = self.model.generate_content(context_prompt)

            # Extract the text from the response
            if response.candidates and response.candidates[0].content.parts:
                return response.candidates[0].content.parts[0].text
            else:
                return "I couldn't generate a response to your query. Please try rephrasing your question."

        except Exception as e:
            app_logger.error(f"Error generating content with Gemini: {str(e)}")
            raise AIServiceException(f"Failed to generate content with AI model: {str(e)}")

    def _extract_citations(self, relevant_content: List[Dict[str, Any]]) -> List[Citation]:
        """Extract citations from relevant content."""
        citations = []

        for content in relevant_content:
            citation = Citation(
                source=content.get("metadata", {}).get("title", "Textbook Content"),
                snippet=content.get("text", "")[:200] + "..." if len(content.get("text", "")) > 200 else content.get("text", ""),
                link=content.get("metadata", {}).get("link", None)
            )
            citations.append(citation)

        return citations

    async def get_chat_history(self, session_id: str) -> List[ChatInteraction]:
        """Retrieve chat history for a specific session."""
        try:
            interactions = await self.chat_history_repo.find_many({"session_id": session_id})
            # Sort by creation time
            interactions.sort(key=lambda x: x.created_at)
            return interactions
        except Exception as e:
            app_logger.error(f"Error retrieving chat history: {str(e)}")
            raise AIServiceException(f"Failed to retrieve chat history: {str(e)}")

    async def save_feedback(self, interaction_id: str, rating: int, comment: Optional[str] = None) -> bool:
        """Save feedback for a chat interaction."""
        try:
            # In a real implementation, we would update the interaction with feedback
            update_data = {
                "feedback_rating": rating
            }
            if comment:
                update_data["feedback_comment"] = comment

            updated_interaction = await self.chat_history_repo.update(interaction_id, update_data)
            return updated_interaction is not None
        except Exception as e:
            app_logger.error(f"Error saving feedback: {str(e)}")
            raise AIServiceException(f"Failed to save feedback: {str(e)}")